{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70438ad6-4645-43f1-9b03-a692dc4d98bc",
   "metadata": {},
   "source": [
    "This notebook documents the analysis of intercellular spaces in live cerebral organoids,described in the manuscript.\n",
    "\n",
    "## Analysis Workflow\n",
    "1. **Segmentation, via 'otsu.py'**\n",
    "   - High signal-to-background enabled robust global thresholding.  \n",
    "   - Otsu’s method + empirically defined offset applied frame by frame.  \n",
    "   - Binary masks generated and overlaid with raw images for QC in Napari.  \n",
    "   - Segmentation errors corrected manually with Napari’s interactive labeling tools.\n",
    "   - Export pixel stats as in csv. files\n",
    "\n",
    "2. **Quantification**  \n",
    "   - Space ratio = (segmented intercellular space area ÷ total image area).  \n",
    "   - Temporal variability assessed by fitting space-ratio time series with linear regression and computing RMSE of residuals.  \n",
    "\n",
    "## Outputs  \n",
    "- Binary masks of intercellular spaces (QC’ed manually).  \n",
    "- Overlays of masks with raw images.  \n",
    "- Summaries of space ratio values.  \n",
    "- Temporal variability metrics (linear regression slope, RMSE).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44369478-b833-496b-aec1-34167862cdde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1717b07-99a0-4249-a063-4a2f23251e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports#\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from pathlib import Path\n",
    "import openpyxl\n",
    "from statistics import mean \n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import itertools\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import statsmodels.stats.multitest as multitest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b047a5fb-334f-4660-9179-5f36143b5683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7542347e-52c5-4b2c-aa6b-57922e124dd9",
   "metadata": {},
   "source": [
    "### Step1: read and process csv. data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475921ce-2a7b-4e02-84c5-4fc24d196b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"input_folder_name\" #folder containing csv. files generated by segmentation pipeline\n",
    "\n",
    "plot_dir_deg1 = os.path.join(base_folder, \"polyfit_deg1_plots\") #define output folder for plots \n",
    "os.makedirs(plot_dir_deg1, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5479aa1d-0875-481c-bfe3-40678e360422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === FUNCTION TO ANALYZE A CSV ===\n",
    "## compute: space rate per time points, mean space rate in a track, and rmse based on linear regression\n",
    "\n",
    "def analyze_csv(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Get time and space rate\n",
    "    time = df[\"Slice Index\"].values\n",
    "    space_rate = df[\"Pixel Count\"].values / df[\"Total Pixels\"].values\n",
    "    filename = Path(file_path).stem\n",
    "    mean_rate = np.mean(space_rate)\n",
    "    std_rate = np.std(space_rate)\n",
    "\n",
    "    metrics = {\n",
    "        \"file\": str(file_path),\n",
    "        \"condition\": Path(file_path).parent.name,\n",
    "        \"mean_rate\": mean_rate,\n",
    "        \"std_rate\": std_rate,\n",
    "        \"time\": time[-1]\n",
    "    }\n",
    "\n",
    "    # === DEGREE 1 POLYNOMIAL FIT ===\n",
    "    coeffs1 = np.polyfit(time, space_rate, deg=1)\n",
    "    predicted1 = np.polyval(coeffs1, time)\n",
    "    residuals1 = space_rate - predicted1\n",
    "    rmsd1 = np.sqrt(np.mean(residuals1 ** 2))\n",
    "    metrics[\"residual_rmsd_deg1\"] = rmsd1\n",
    "\n",
    "    # === PLOT ===\n",
    "    ## visualize the space rate over time and linear regression fitting, per plot per csv. file\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(time, space_rate, 'o-', label=\"Space Rate\")\n",
    "    plt.plot(time, predicted1, 'r--', label=f\"Poly Deg 1 (RMSD={rmsd1:.4f})\")\n",
    "    plt.axhline(mean_rate, color='gray', linestyle=':', label=f\"Mean = {mean_rate:.3f} (RMSE={rmse_mean:.4f})\")\n",
    "    plt.xlabel(\"Slice Index\")\n",
    "    plt.ylabel(\"Space Rate\")\n",
    "    plt.ylim(0.05, 0.40)\n",
    "    plt.title(f\"PolyFit (1°) + Mean RMSE: {filename}\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plot_dir_deg1, f\"{filename}_fit-deg1_mean.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6be3a7-bd19-4a24-91b0-b170c26eec5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Main loop: collect and analyze all CSVs ===\n",
    "results = []\n",
    "\n",
    "for root, dirs, files in os.walk(base_folder):\n",
    "    for file in files:\n",
    "        if file.lower().endswith(\".csv\"):\n",
    "            file_path = os.path.join(root, file)\n",
    "            try:\n",
    "                metrics = analyze_csv(file_path)\n",
    "                results.append(metrics)\n",
    "                print(f\"Processed: {file_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error processing {file_path}: {e}\")\n",
    "\n",
    "# === Save results to Excel ===\n",
    "output_excel_path = os.path.join(base_folder, \"space_rate_metrics.xlsx\")\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_excel(output_excel_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7385388b-5c5c-4a58-bfa6-fe5ece7add62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970822d5-a44f-45b9-a406-6f02932f5ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38902401-0673-4bc9-9f56-3f96bac82b4e",
   "metadata": {},
   "source": [
    "### Step2: visualize all data (real-time space value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c464784d-d9ed-4d83-aabe-ee5ed662fd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== section1: organize data to prepare for plot drawing, by concatenate all csv. data into 1 excel. sheet\n",
    "\n",
    "input_folder_path = \"input_folder_name\" # folder where csv. files locate\n",
    "\n",
    "figure_save = 'output_folder_name' # define output folder for generated plots\n",
    "output_excel = 'output_excel_name' # define output excel to contain concatenated csv. data\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for file in os.listdir(input_folder_path):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(input_folder_path, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "        df['time'] = df['Slice Index'] * 5 # interval: 5 min\n",
    "        df['space_rate'] = df['Pixel Count'] / df['Total Pixels']\n",
    "        df['index'] = os.path.splitext(file)[0]  # filename without extension\n",
    "\n",
    "        all_data.append(df)\n",
    "\n",
    "\n",
    "combined_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "\n",
    "combined_df.to_excel(output_excel, index=False)\n",
    "print(f\"✅ Combined data saved to: {output_excel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506e9140-e755-4067-9639-dd9767c479a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== section2: draw trajectory plot\n",
    "\n",
    "## read data\n",
    "file_path = output_excel \n",
    "df = pd.read_excel(file_path)\n",
    "print(df.head())\n",
    "\n",
    "figure_name = os.path.splitext(os.path.basename(file_path))[0] \n",
    "\n",
    "grouped = df.groupby('index') # group by index, which means conditions\n",
    "\n",
    "filtered_groups = {name: group.iloc[:8] for name, group in grouped if len(group) >= 8} # filter valid groups (≥ 8 rows, only read first 8 rows)\n",
    "filtered_df = pd.concat(filtered_groups.values(), ignore_index=True)\n",
    "\n",
    "\n",
    "## Plot All Trajectories \n",
    "plt.figure(figsize=(6, 4))\n",
    "for name, group in filtered_df.groupby('index'):\n",
    "    plt.scatter(group['time'], group['space_rate'], s=40, alpha=0.4)\n",
    "    plt.plot(group['time'], group['space_rate'], alpha=0.5, linewidth=1)\n",
    "\n",
    "plt.xlabel('time', fontsize=12)\n",
    "plt.ylabel('space_rate)', fontsize=12)\n",
    "plt.title(f'{figure_name} - All Trajectories', fontsize=12)\n",
    "\n",
    "plt.gca().xaxis.set_major_locator(ticker.MultipleLocator(5))\n",
    "plt.xlim(0, 35)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{figure_save}/{figure_name}_all_trajs.pdf\")\n",
    "plt.show()\n",
    "\n",
    "summary_save_path = os.path.join(figure_save, f\"{figure_name}_group_summary.txt\")\n",
    "\n",
    "\n",
    "# Plot Mean+std Trajectories ---\n",
    "pivot_table = filtered_df.pivot_table(index='time', columns='index', values='space_rate')\n",
    "\n",
    "mean_values = pivot_table.mean(axis=1)\n",
    "std_values = pivot_table.std(axis=1)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(mean_values.index, mean_values.values, color='black', linewidth=2, label='Mean')\n",
    "plt.fill_between(mean_values.index, mean_values - std_values, mean_values + std_values, color='gray', alpha=0.5, label='Mean ± SD')\n",
    "\n",
    "plt.gca().xaxis.set_major_locator(ticker.MultipleLocator(5))\n",
    "\n",
    "plt.xlim(0, 35)\n",
    "\n",
    "plt.title(f\"{figure_name} - Normalized Mean ± SD\", fontsize=12)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{figure_save}/{figure_name}_mean+sd.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5006103-dad2-489a-aaf9-655564e864f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
