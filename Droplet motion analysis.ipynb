{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8f74907-28da-466b-ad05-558b13784862",
   "metadata": {},
   "source": [
    "This notebook reproduces the **trajectory filtering, instantenous speed, and MSD analysis** described in the manuscript.  \n",
    "\n",
    "## Analysis Workflow\n",
    "- **Preprocessing**  \n",
    "  - Walk through subfolders of TrackMate outputs (CSV files containing ‚Äúedge‚Äù or ‚Äúspot‚Äù).\n",
    "        [NOTE:edge.csv is used to extract the instantaneous speed, and spot.csv is used to analyse MSD; assuming the csv files for each condition (stage*species) is concetenate into 1 file]\n",
    "  - Clean headers and sort trajectories by time.\n",
    "  - Add derived columns:\n",
    "    - `time` (row index √ó frame interval, in minutes)\n",
    "    - `index` (track identifier combining TRACK_ID and file name)\n",
    "  - Plot SPEED vs. time for each trajectory and save figures.\n",
    "  - Merge trajectories per subfolder and save as Excel files.\n",
    "\n",
    "\n",
    "- **Filtering**  \n",
    "  - Keep only trajectories with ‚â• 31 time points (i.e., 150 min duration)\n",
    "  - Truncate to first 31 time points for consistency  \n",
    "\n",
    "- **MSD Computation**  \n",
    "  - Project 2D droplet coordinates (X, Y) onto the principal motion axis using PCA  \n",
    "  - Compute 1D mean squared displacement (MSD) across time lags  \n",
    "\n",
    "- **Model Fitting**  \n",
    "  - Fit MSD curves to a power-law model**:  \n",
    "    \\[\n",
    "    MSD(\\Delta t) \\sim A \\cdot (\\Delta t)^\\alpha\n",
    "    \\]  \n",
    "  - Extract anomalous exponent Œ± per droplet:  \n",
    "    - Œ± = 1 ‚Üí Brownian diffusion  \n",
    "    - Œ± < 1 ‚Üí Subdiffusion  \n",
    "    - Œ± > 1 ‚Üí Superdiffusion  \n",
    "\n",
    "- **Outputs**  \n",
    "  - SPEED vs. time plots per merged csv\n",
    "  - Merged and filtered Excel files of trajectories.\n",
    "  - Per-droplet MSD curves (linear).\n",
    "  - Per-droplet Œ± values (Excel summary).\n",
    "  - Population mean ¬± SD MSD curves with power-law fit.\n",
    "  - Histogram of Œ± distribution across droplets.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18abc1b2-9074-43a9-8e34-b45763be8bc7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d5aa48-5aae-4828-b9bd-fb47537b3056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "from statistics import mean\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa72849-b12b-46ef-8caa-63e1edf0e7f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c49f784-3340-435c-a9b4-86c01606b5da",
   "metadata": {},
   "source": [
    "# Part1: instantenous speed analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d326cb-0041-48ad-a2a8-7538fbf59274",
   "metadata": {},
   "source": [
    "### Step1 : Preprocessing and CSV merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1778c29c-5306-4227-82e0-5143ae7208db",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = 'base_folder_name' ## structure: base_folder >> subfolder >> csv. files\n",
    "output_folder_merged_data = \"outpout_folder_name\"\n",
    "\n",
    "for root, dirs, files in os.walk(base_folder):\n",
    "    edge_files = [f for f in files if f.endswith(\".csv\") and \"edge\" in f.lower()]\n",
    "    \n",
    "    if edge_files:\n",
    "        print(f\"\\nüìÇ Processing subfolder: {root}\")\n",
    "        subfolder_name = os.path.basename(root.rstrip(\"/\\\\\"))\n",
    "        combined_dfs = []\n",
    "\n",
    "        for file in edge_files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            df = pd.read_csv(file_path, skiprows=[1, 2, 3]) # remove redundant headers\n",
    "            df.columns = df.columns.str.strip()\n",
    "            df = df.sort_values(by=\"EDGE_TIME\").reset_index(drop=True)\n",
    "            df[\"time\"] = df.index * 5 # time interval: 5min\n",
    "            base_name = os.path.splitext(file)[0]\n",
    "            df[\"index\"] = df[\"TRACK_ID\"].astype(str) + \"_\" + base_name\n",
    "\n",
    "            combined_dfs.append(df)\n",
    "\n",
    "        if combined_dfs:\n",
    "            pd.concat(combined_dfs, ignore_index=True).to_excel(\n",
    "                f\"{output_folder_merged_data}{subfolder_name}.xlsx\", index=False\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2c4837-a28a-41d3-a339-6b704bbf00bb",
   "metadata": {},
   "source": [
    "### Step2 : Trajectory plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b04408-a625-482e-8e85-0bd270a95279",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "figure_save = 'outout_figure_pathway'\n",
    "file_path = \"file_name.xlsx\"\n",
    "figure_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "\n",
    "\n",
    "# --- Plot All Trajectories ---\n",
    "df = pd.read_excel(file_path)\n",
    "df['SPEED'] = df['SPEED']*60 # convert speed unit from micron/second into micron/minutes\n",
    "grouped = df.groupby('index')\n",
    "filtered_groups = {name: group.iloc[:31] for name, group in grouped if len(group) >= 31}\n",
    "filtered_df = pd.concat(filtered_groups.values(), ignore_index=True)\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "for name, group in filtered_df.groupby('index'):\n",
    "    plt.scatter(group['time'], group['SPEED'], s=20, alpha=0.8)\n",
    "    plt.plot(group['time'], group['SPEED'], alpha=0.7, linewidth=0.7)\n",
    "\n",
    "plt.xlabel('time', fontsize=10)\n",
    "plt.ylabel('real-time-speed per displacement', fontsize=10)\n",
    "plt.title(f'{figure_name} - All Trajectories', fontsize=12)\n",
    "plt.gca().xaxis.set_major_locator(ticker.MultipleLocator(25))\n",
    "plt.xlim(5, 150) \n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{figure_save}/{figure_name}.pdf\")\n",
    "plt.show()\n",
    "\n",
    "summary_save_path = os.path.join(figure_save, f\"{figure_name}_group_summary.txt\")\n",
    "\n",
    "# --- mean+std Trajectories ---\n",
    "\n",
    "pivot_table = filtered_df.pivot_table(index='time', columns='index', values='SPEED')\n",
    "\n",
    "mean_values = pivot_table.mean(axis=1)\n",
    "std_values = pivot_table.std(axis=1)\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.plot(mean_values.index, mean_values.values, color='black', linewidth=2, label='Mean')\n",
    "plt.fill_between(mean_values.index, mean_values - std_values, mean_values + std_values, color='gray', alpha=0.5, label='Mean ¬± SD')\n",
    "\n",
    "plt.xlabel('time', fontsize=10)\n",
    "plt.ylabel('real-time-speed per displacement', fontsize=10)\n",
    "plt.gca().xaxis.set_major_locator(ticker.MultipleLocator(25))\n",
    "\n",
    "plt.xlim(5, 150)\n",
    "plt.ylim(-0.2, 1.6)\n",
    "\n",
    "plt.title(f\"{figure_name} - Normalized Mean ¬± SD\", fontsize=12)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{figure_save}/{figure_name}_mean+sd.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c387ff-d531-4305-954f-5d234d35816d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0784362-8b15-4cae-840f-e9458a795497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4496a50-171c-4319-8f0e-4353f6fa6b75",
   "metadata": {},
   "source": [
    "# Part2: MSD analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cf3c6d-5ed0-4b0a-a2ac-93cc4a247ca0",
   "metadata": {},
   "source": [
    "### Step1 : Filter to 31 time points, process data for msd analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b0ac6dc-de4d-45e6-9acf-fcab4c437535",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"input_folder_name\"\n",
    "output_folder_31 = \"output_folder_name\" ## 31 time points correspond to the first 150 min\n",
    "os.makedirs(output_folder_31, exist_ok=True)\n",
    "\n",
    "def filter_to_first_31_rows(input_folder, output_folder):\n",
    "    for file in os.listdir(input_folder):\n",
    "        if file.endswith(\".xlsx\") and \"spots_merged\" in file:\n",
    "            file_path = os.path.join(input_folder, file)\n",
    "            print(f\"üîπ Processing: {file}\")\n",
    "            df = pd.read_excel(file_path)\n",
    "            filtered = (\n",
    "                df.groupby(\"index\")\n",
    "                  .filter(lambda x: len(x) >= 31)\n",
    "                  .groupby(\"index\")\n",
    "                  .head(31)\n",
    "                  .reset_index(drop=True)\n",
    "            )\n",
    "            output_file = file.replace(\"_spots_merged.xlsx\", \"_spots_31points.xlsx\")\n",
    "            output_path = os.path.join(output_folder, output_file)\n",
    "            filtered.to_excel(output_path, index=False)\n",
    "            print(f\"‚úÖ Saved filtered file: {output_file}\")\n",
    "\n",
    "filter_to_first_31_rows(input_folder, output_folder_31)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee40044-58fb-4a65-ade9-c1ac6b348a74",
   "metadata": {},
   "source": [
    "### Step2 : MSD computation & Œ± fitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18116424-54f7-44c2-a847-f80c8ccd2c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "time_interval = 5\n",
    "\n",
    "# Power-law model for alpha fitting #\n",
    "def power_law(t, A, alpha):\n",
    "    return A * t ** alpha\n",
    "\n",
    "# Compute 1D MSD using PCA per droplet #\n",
    "def compute_1d_msd_pca(df, time_col='time', pos_cols=['X', 'Y'], index_col='index', min_len=31):\n",
    "    all_results = []\n",
    "    for track_id, group in df.groupby(index_col):\n",
    "        if len(group) < min_len:\n",
    "            continue\n",
    "        group = group.sort_values(by=time_col).reset_index(drop=True)\n",
    "        pos = group[pos_cols].values\n",
    "        pca = PCA(n_components=1)\n",
    "        proj = pca.fit_transform(pos).flatten()\n",
    "        n = len(proj)\n",
    "        for tau in range(1, n):\n",
    "            displacements = proj[tau:] - proj[:-tau]\n",
    "            msd = np.mean(displacements**2)\n",
    "            all_results.append({\"index\": track_id, \"lag\": tau * time_interval, \"MSD_1D\": msd})\n",
    "    return pd.DataFrame(all_results)\n",
    "\n",
    "# Fit alpha per 1D MSD curve \n",
    "def estimate_alpha_from_1d_msd(msd_df_1d):\n",
    "    alpha_list = []\n",
    "    for idx, group in msd_df_1d.groupby(\"index\"):\n",
    "        try:\n",
    "            lags = group[\"lag\"].values\n",
    "            msd = group[\"MSD_1D\"].values\n",
    "            if np.max(msd) < 10:\n",
    "                continue\n",
    "            popt, _ = curve_fit(power_law, lags, msd, bounds=([0, 0], [np.inf, 3]))\n",
    "            A, alpha = popt\n",
    "            alpha_list.append({\"index\": idx, \"A\": A, \"alpha_1D\": alpha})\n",
    "        except:\n",
    "            continue\n",
    "    return pd.DataFrame(alpha_list)\n",
    "\n",
    "# Plot MSDs colored by alpha \n",
    "def plot_1d_msd_colored_by_alpha(msd_df_1d, alpha_df, label, save_dir):\n",
    "    merged = pd.merge(msd_df_1d, alpha_df, on=\"index\", how=\"inner\")\n",
    "    cmap = cm.coolwarm\n",
    "    norm = Normalize(vmin=0, vmax=2)\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    for scale in ['linear', 'loglog']:\n",
    "        fig, ax = plt.subplots(figsize=(5, 3))\n",
    "        plt.rcParams['font.family'] = 'Arial'\n",
    "\n",
    "        for idx, group in merged.groupby(\"index\"):\n",
    "            alpha_val = group[\"alpha_1D\"].iloc[0]\n",
    "            ax.plot(group[\"lag\"], group[\"MSD_1D\"], color=cmap(norm(alpha_val)), alpha=0.5)\n",
    "\n",
    "        mean_msd = merged.groupby(\"lag\")[\"MSD_1D\"].mean()\n",
    "        ax.plot(mean_msd.index, mean_msd.values, color=\"black\", linewidth=2, label=\"Mean MSD\")\n",
    "\n",
    "        sm = cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "        sm.set_array([])\n",
    "        cbar = fig.colorbar(sm, ax=ax)\n",
    "        cbar.set_label(\"Œ± (diffusion exponent)\")\n",
    "\n",
    "        plt.xlim (0,150)\n",
    "\n",
    "        ax.set_title(f\"1D MSD ({scale.capitalize()}): {label}\",fontsize=12)\n",
    "        ax.set_xlabel(\"Time lag (min)\",fontsize=10)\n",
    "        ax.set_ylabel(\"MSD (Œºm¬≤)\",fontsize=10)\n",
    "\n",
    "        if scale == \"loglog\":\n",
    "            ax.set_xscale(\"log\")\n",
    "            ax.set_yscale(\"log\")\n",
    "            ax.set_ylabel(\"MSD (Œºm¬≤, log)\")\n",
    "\n",
    "        ax.grid(True, which='both', ls='--')\n",
    "        ax.legend()\n",
    "        fig.tight_layout()\n",
    "\n",
    "        fig.savefig(os.path.join(save_dir, f\"{label}_1D_MSD_{scale}.pdf\"))\n",
    "        plt.close(fig)\n",
    "\n",
    "def save_msd_and_alpha_to_excel(msd_df, alpha_df, output_path):\n",
    "    with pd.ExcelWriter(output_path) as writer:\n",
    "        msd_df.to_excel(writer, sheet_name=\"1D_MSD\", index=False)\n",
    "        alpha_df.to_excel(writer, sheet_name=\"alpha_summary\", index=False)\n",
    "    print(f\"‚úÖ Excel saved: {output_path}\")\n",
    " \n",
    "def run_pca_1d_analysis(input_df, label, save_dir):\n",
    "    print(f\"üîé Analyzing: {label}\")\n",
    "    \n",
    "    msd_1d_df = compute_1d_msd_pca(input_df)\n",
    "    alpha_df = estimate_alpha_from_1d_msd(msd_1d_df)\n",
    "\n",
    "    excel_path = os.path.join(save_dir, f\"{label}_PCA_1D_MSD.xlsx\")\n",
    "    save_msd_and_alpha_to_excel(msd_1d_df, alpha_df, excel_path)\n",
    "\n",
    "    plot_1d_msd_colored_by_alpha(msd_1d_df, alpha_df, label, save_dir)\n",
    "\n",
    "    return msd_1d_df, alpha_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410277af-2800-4c82-bcb1-53420657910f",
   "metadata": {},
   "source": [
    "### Step5: Run analysis on example dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909b47ad-b3aa-405f-986a-bbcf25baab16",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"///_spots_31points.xlsx\" #define\n",
    "save_folder = \"folder_name\" #define\n",
    "condition_name = \"condition_name\" #define\n",
    "\n",
    "df = pd.read_excel(input_file)\n",
    "\n",
    "# Run full analysis\n",
    "msd_df_1d, alpha_summary_1d = run_pca_1d_analysis(df, condition_name, save_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abd3c01-5027-474a-81ec-4421a8f13964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8688019-b915-48a1-a880-99e3eda907cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4663599-0d34-43b4-a9bd-e76333e175d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
