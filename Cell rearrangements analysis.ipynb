{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a366f944-1fee-4cc6-bb0e-684afdc5dfe3",
   "metadata": {},
   "source": [
    "This notebook reproduces the **quantification of cell rearrangement events** described in the manuscript.  \n",
    "\n",
    "## Analysis Workflow\n",
    "\n",
    "- **Event Identification**\n",
    "  - Junctional changes were manually tracked from time-lapse membrane imaging (≥100 min), in FIJI.\n",
    "  - Events were classified into three categories:\n",
    "    - T1 (Neighbor exchange): one junction shrinks while an orthogonal junction expands, leading to a swap of neighbors.  \n",
    "    - T2 (Cell extrusion): junctions contract around a cell as it exits the basal layer.  \n",
    "    - T3 (Cell insertion): junctions open to accommodate a new cell intercalating into the basal layer.  \n",
    "\n",
    "- **Normalization**\n",
    "  - Rearrangement rates normalized to:\n",
    "    1. The total number of cells in the analyzed region at \\(t=0\\).  \n",
    "    2. The imaging duration.  \n",
    "\n",
    "- **Cumulative Quantification**\n",
    "  - Cumulative rearrangements over time calculated by summing events up to each time point.  \n",
    "  - Values normalized to the initial cell number.  \n",
    "\n",
    "## Outputs\n",
    "- Counts of T1, T2, and T3 events per imaging sequence  \n",
    "- Rearrangement rates (events per cell per unit time)  \n",
    "- Cumulative rearrangement curves normalized to initial cell number  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e0c2b2-f2d7-43da-ae03-3f01605c3d93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d65bf4-69bb-4ca5-99ae-2d3a2ba834f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "import openpyxl\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.cm as cm\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b290cb69-21ca-4277-898d-cd3e121247aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1e3044a-a51a-404e-9b18-4e7dfeba93bd",
   "metadata": {},
   "source": [
    "### Step1: load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e2cd91-b471-4004-bae7-2ba31c239d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'input-file.xlsx'\n",
    "df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
    "\n",
    "output_folder = 'output-folder-path'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56069a29-f6ee-488e-a470-2799c8d68508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a4d4a5f-6468-4fa8-9e1f-0472937eb582",
   "metadata": {},
   "source": [
    "### Step2: data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fce27e-7614-4bc6-af6f-72d4aabf23ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CLEAN COLUMN NAMES === (just in case)\n",
    "df.columns = df.columns.str.strip().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "print(\"✅ Columns:\", df.columns.tolist())\n",
    "\n",
    "# === Add duration in minutes ===\n",
    "df['duration_min'] = (df['time_points'] - 1) * 10  # time in minutes\n",
    "\n",
    "# === Compute normalised rates ===\n",
    "# Per cell → divide by number of cells\n",
    "df['total_rate_per_cell_per_min'] = df['total_rearrange_count'] / (df['duration_min'] * df['cell_number'])\n",
    "df['T1_rate_per_cell_per_min'] = df['t1_count'] / (df['duration_min'] * df['cell_number'])\n",
    "df['T2_rate_per_cell_per_min'] = df['t2_count'] / (df['duration_min'] * df['cell_number'])\n",
    "df['T3_rate_per_cell_per_min'] = df['t3_count'] / (df['duration_min'] * df['cell_number'])\n",
    "\n",
    "# Per area → divide by cropped_region (µm²)\n",
    "df['total_rate_per_um2_per_min'] = df['total_rearrange_count'] / (df['duration_min'] * df['cropped_region'])\n",
    "df['T1_rate_per_um2_per_min'] = df['t1_count'] / (df['duration_min'] * df['cropped_region'])\n",
    "df['T2_rate_per_um2_per_min'] = df['t2_count'] / (df['duration_min'] * df['cropped_region'])\n",
    "df['T3_rate_per_um2_per_min'] = df['t3_count'] / (df['duration_min'] * df['cropped_region'])\n",
    "\n",
    "# === Compute ratios over total_rearrange_count ===\n",
    "df['T1_ratio'] = df['t1_count'] / df['total_rearrange_count']\n",
    "df['T2_ratio'] = df['t2_count'] / df['total_rearrange_count']\n",
    "df['T3_ratio'] = df['t3_count'] / df['total_rearrange_count']\n",
    "\n",
    "display(df)\n",
    "df.to_excel(f'{output_folder}total_rates_output-20250703.xlsx', index=False)\n",
    "\n",
    "print(\"✅ Computed normalised rates PER MINUTE and saved to summary_with_rates.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7980d45-c2a6-45ef-a0ca-214d49603e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25041115-964b-48ba-93f1-7765f023c176",
   "metadata": {},
   "source": [
    "### Step3: calculate and visualize the proportion of transition events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aef7193-c3a3-4311-bec4-c345ed419993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === GROUP BY 'Condition' AND COMPUTE RATIOS ===\n",
    "grouped = df.groupby('Condition')[['total_rearrange_count', 't1_count', 't2_count', 't3_count']].sum()\n",
    "ratios_df = grouped[['t1_count','t2_count','t3_count']].div(grouped['total_rearrange_count'], axis=0)\n",
    "ratios_df.columns = ['T1_ratio', 'T2_ratio', 'T3_ratio']\n",
    "print(ratios_df)\n",
    "\n",
    "# === STACKED BAR PLOT ===\n",
    "ax = ratios_df.plot(\n",
    "    kind='bar',\n",
    "    stacked=True,\n",
    "    figsize=(3, 4),\n",
    "    color=['#ff7f0e', '#2ca02c', '#1f77b4'],\n",
    "    alpha=0.8\n",
    ")\n",
    "\n",
    "plt.ylabel('Ratio of total rearrangements (%)', fontsize=10)\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylim(0, 1)\n",
    "plt.legend(['T1', 'T2', 'T3'], title='Transition Type')\n",
    "plt.tight_layout()\n",
    "\n",
    "plot_file = f\"{output_folder}t1-2-3ratio.pdf\"\n",
    "plt.savefig(plot_file, format='pdf')\n",
    "plt.show()\n",
    "print(f\"✅ Stacked bar plot saved → {plot_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d37f1ec-5ab8-48e3-8e55-ca4a8a6d1591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9938423-6cdd-4e51-b39f-d7ce9cb92830",
   "metadata": {},
   "source": [
    "### Step4: cumulative transition events analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104a4534-bd7f-4a47-be36-93ce7cd820f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path(\"base_folder\") # structure: base_folder >> subfolder {condition} >>  csv. containing counted dots at certain time points\n",
    "conditions = [\"condition1\", \"condition2\", \"condition3\", \"condition4\", \"condition5\"] # named as condition settings\n",
    "extensions = {\".csv\"}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd460b7-aa25-4bbb-bf1e-2bf07c4d1d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === define functions to concatenate data for each condition\n",
    "rows = []\n",
    "for cond in conditions:\n",
    "    folder = base_dir / cond\n",
    "    for p in folder.glob(\"*\"):\n",
    "        if p.is_file() and p.suffix.lower() in extensions:\n",
    "            rows.append({\n",
    "                \"filename\": p.name,                         \n",
    "                \"cell_count\": \"\",                           \n",
    "                \"condition\": cond,                         \n",
    "                \"rel_path\": str(p.relative_to(base_dir)),   \n",
    "                \"abs_path\": str(p.resolve())                \n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(rows).sort_values([\"condition\", \"filename\"])\n",
    "\n",
    "excel_out = base_dir / \"cell_counts_template.xlsx\"\n",
    "csv_out   = base_dir / \"cell_counts_template.csv\"\n",
    "with pd.ExcelWriter(excel_out, engine=\"openpyxl\") as w:\n",
    "    df.to_excel(w, index=False, sheet_name=\"cell_counts\")\n",
    "df.to_csv(csv_out, index=False)\n",
    "\n",
    "print(f\"Made:\\n- {excel_out}\\n- {csv_out}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fa8a27-9090-4146-811a-fcd4809d2750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === define plotting function\n",
    "mapping_path = base_dir / \"cell_counts.xlsx\"  # or .csv with same columns\n",
    "data_ext = \".csv\"\n",
    "frame_interval_min = 10\n",
    "target_time_points = 10                       # for mean±SD panel only\n",
    "out_dir = base_dir / \"plots\"\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "# ------------------------------------------------\n",
    "\n",
    "fixed_colors = {\n",
    "    \"condition1\": \"#0072B2\",\n",
    "    \"condition2\": \"#E69F00\",\n",
    "    \"condition3\": \"#D55E00\",\n",
    "    \"condition4\": \"#009E73\",\n",
    "    \"condition5\": \"#CC79A7\",\n",
    "}\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def load_mapping(p: Path) -> pd.DataFrame:\n",
    "    \"\"\"Needs: rel_path, condition, cell_count, time_points.\"\"\"\n",
    "    if p.suffix.lower() == \".csv\":\n",
    "        df = pd.read_csv(p)\n",
    "    else:\n",
    "        df = pd.read_excel(p, sheet_name=0)\n",
    "    needed = {\"rel_path\", \"condition\", \"cell_count\", \"time_points\"}\n",
    "    missing = needed - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Mapping file missing columns: {missing}\")\n",
    "    df[\"rel_path\"] = df[\"rel_path\"].astype(str)\n",
    "    return df\n",
    "\n",
    "def insert_zero_frame(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Ensure (t=0, count=0) exists as baseline.\"\"\"\n",
    "    if \"t\" not in df.columns or \"count\" not in df.columns:\n",
    "        raise ValueError(\"Dataframe must have columns 't' and 'count'.\")\n",
    "    if 0.0 not in df[\"t\"].values:\n",
    "        df = pd.concat([pd.DataFrame({\"t\":[0.0], \"count\":[0]}), df], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def build_trace_individual(file_path: Path, cell_count: int, time_points: int):\n",
    "    \"\"\"\n",
    "    INDIVIDUAL TRACES:\n",
    "    - Use the whole CSV but cut at 'time_points'.\n",
    "    - Insert (0,0) if missing, then shift t -> t+1 so index 0 is baseline.\n",
    "    - No padding beyond 'time_points'.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = insert_zero_frame(df)\n",
    "\n",
    "    frames = df[\"t\"].round().astype(int).to_numpy() + 1   # shift\n",
    "    counts = df[\"count\"].to_numpy()\n",
    "\n",
    "    T = int(time_points)\n",
    "    counts_per_frame = np.zeros(T, dtype=float)\n",
    "    for fr, ct in zip(frames, counts):\n",
    "        if 0 <= fr < T:\n",
    "            counts_per_frame[fr] += ct\n",
    "\n",
    "    cum = np.cumsum(counts_per_frame)\n",
    "    norm_cum = cum / float(cell_count)\n",
    "    time_min = np.arange(T) * frame_interval_min\n",
    "    return time_min, norm_cum\n",
    "\n",
    "def build_trace_meanstd(file_path: Path, cell_count: int, target_T: int = 10):\n",
    "    \"\"\"\n",
    "    MEAN±SD PANEL:\n",
    "    - Read only the first 'target_T' rows from CSV.\n",
    "    - Insert (0,0) if missing, shift t -> t+1.\n",
    "    - Return fixed-length arrays of length 'target_T'.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path, nrows=target_T)\n",
    "    df = insert_zero_frame(df)\n",
    "\n",
    "    frames = df[\"t\"].round().astype(int).to_numpy() + 1   # shift\n",
    "    counts = df[\"count\"].to_numpy()\n",
    "\n",
    "    counts_per_frame = np.zeros(target_T, dtype=float)\n",
    "    for fr, ct in zip(frames, counts):\n",
    "        if 0 <= fr < target_T:\n",
    "            counts_per_frame[fr] += ct\n",
    "\n",
    "    cum = np.cumsum(counts_per_frame)\n",
    "    norm_cum = cum / float(cell_count)\n",
    "    time_min = np.arange(target_T) * frame_interval_min\n",
    "    return time_min, norm_cum\n",
    "\n",
    "def fit_through_origin(x: np.ndarray, y: np.ndarray):\n",
    "    \"\"\"Return slope, R^2, and fitted y for a line forced through origin.\"\"\"\n",
    "    x = x.astype(float); y = y.astype(float)\n",
    "    sxx = np.dot(x, x)\n",
    "    sxy = np.dot(x, y)\n",
    "    slope = sxy / sxx if sxx != 0 else np.nan\n",
    "    yhat = slope * x\n",
    "    ss_res = np.sum((y - yhat) ** 2)\n",
    "    ss_tot = np.sum((y - y.mean()) ** 2)\n",
    "    r2 = 1.0 - ss_res / ss_tot if ss_tot != 0 else np.nan\n",
    "    return slope, r2, yhat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d1a6b4-5926-4ad1-be6c-5154a6bb4069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === call defined function\n",
    "mapping = load_mapping(mapping_path)\n",
    "conditions_in_data = list(pd.unique(mapping[\"condition\"]))\n",
    "color_map = {c: fixed_colors.get(c, plt.cm.tab20(i % 20)) for i, c in enumerate(conditions_in_data)}\n",
    "\n",
    "# Storage\n",
    "raw_traces = {c: [] for c in conditions_in_data}   # (time, trace) with actual time_points\n",
    "per_condition_fixed = {c: [] for c in conditions_in_data}  # fixed length (10) for mean±SD\n",
    "rep_counts = {c: 0 for c in conditions_in_data}\n",
    "time_axis_fixed = np.arange(target_time_points) * frame_interval_min\n",
    "\n",
    "for _, row in mapping.iterrows():\n",
    "    fpath = base_dir / row[\"rel_path\"]\n",
    "    if not (fpath.is_file() and fpath.suffix.lower() == data_ext):\n",
    "        continue\n",
    "    cond = row[\"condition\"]\n",
    "    cells = int(row[\"cell_count\"])\n",
    "    tpts = int(row[\"time_points\"])\n",
    "\n",
    "    # individual (stop at time_points)\n",
    "    t_ind, tr_ind = build_trace_individual(fpath, cells, time_points=tpts)\n",
    "    raw_traces[cond].append((t_ind, tr_ind))\n",
    "\n",
    "    # mean±SD (first 10 rows, t->t+1)\n",
    "    _, tr_fix = build_trace_meanstd(fpath, cells, target_T=target_time_points)\n",
    "    per_condition_fixed[cond].append(tr_fix)\n",
    "\n",
    "    rep_counts[cond] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90baab6-0fb8-4c71-a843-0b6ffba74b08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd4d7479-2e98-4a1b-b97a-f28cc9cad518",
   "metadata": {},
   "source": [
    "## Step5: cumulative transition events visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61853413-3d6e-4425-870a-04eae209f5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- PLOT 1: individual traces — one PDF per condition --------------------\n",
    "global_ymax = 0.0\n",
    "for cond in conditions:\n",
    "    if raw_traces[cond]:\n",
    "        global_ymax = max(global_ymax, max(tr.max() for _, tr in raw_traces[cond]))\n",
    "ylims = (0, global_ymax * 1.05)  # 5% headroom\n",
    "\n",
    "for cond in conditions:\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    ax.set_title(f\"{cond} (n={rep_counts[cond]})\")\n",
    "    ax.set_xlabel(\"Time [min]\")\n",
    "    ax.set_ylabel(\"Cumulative transitions / cell\")\n",
    "\n",
    "    n_traces = len(raw_traces[cond])\n",
    "    cmap = cm.get_cmap(\"tab20\", n_traces)  \n",
    "\n",
    "    for idx, (tmin, tr) in enumerate(raw_traces[cond]):\n",
    "        ax.plot(tmin, tr, color=cmap(idx), alpha=0.8, lw=2, label=f\"trace {idx+1}\")\n",
    "\n",
    "    ax.grid(True, alpha=0.25)\n",
    "    ax.set_ylim(*ylims)                           \n",
    "\n",
    "    outfile = out_dir / f\"individual_{cond}.pdf\"\n",
    "    ax.set_xlim(0, 90)\n",
    "    ax.set_ylim(0, 0.4)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(outfile)                \n",
    "    plt.show(fig)\n",
    "\n",
    "# # -------------------- PLOT 2: mean ± SD + linear fit (through origin) --------------------\n",
    "plt.figure(figsize=(6, 5))\n",
    "for cond in conditions:\n",
    "    traces = per_condition_fixed[cond]\n",
    "    if not traces:\n",
    "        continue\n",
    "    M = np.vstack(traces)     # n_rep x 10\n",
    "    mean = M.mean(axis=0)\n",
    "    std  = M.std(axis=0)\n",
    "\n",
    "    slope, r2, yhat = fit_through_origin(time_axis_fixed, mean)\n",
    "\n",
    "    # Print slopes\n",
    "    print(f\"{cond}: slope={slope:.4f} per min | {slope*frame_interval_min:.4f} per 10-min frame | R^2={r2:.3f}\")\n",
    "\n",
    "    c = color_map[cond]\n",
    "    plt.plot(time_axis_fixed, mean,\n",
    "             label=f\"{cond} (n={rep_counts[cond]}) — slope={slope:.3f}, R²={r2:.3f}\",\n",
    "             color=c, lw=2.6)\n",
    "    plt.fill_between(time_axis_fixed, mean - std, mean + std, color=c, alpha=0.20, linewidth=0)\n",
    "    plt.plot(time_axis_fixed, yhat, color=c, linestyle=\"--\", lw=1.6, alpha=0.85)\n",
    "\n",
    "plt.xlabel(\"Time [min]\")\n",
    "plt.ylabel(\"Cumulative transitions / cell\")\n",
    "plt.title(\"Mean ± SD with linear fit through origin (first 10 rows; t → t+1; t=0 inserted)\")\n",
    "plt.grid(True, alpha=0.25)\n",
    "plt.xlim(0, time_axis_fixed[-1])\n",
    "plt.legend(frameon=False, fontsize=9, ncol=2)\n",
    "plt.tight_layout()\n",
    "plt.savefig(out_dir / \"mean_sd_with_regression_origin.pdf\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
